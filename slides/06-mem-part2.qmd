---
title: "GestiÃ³ de la MemÃ²ria (Part II)"
subtitle: "Unitat 6 Â· Sistemes Operatius (SO)"
author: "Jordi Mateo FornÃ©s"
logo: "/figures/corporative/institute.png"
format: 
  revealjs:
    transition: fade
    slide-number: true
    incremental: true 
    chalkboard: false
    css: styles.css
    pdf-separate-fragments: false
    pdf-max-pages-per-slide: 1
    pdf-page-height: 900
    pdf-page-width: 1600
    footer: "Unitat 6 Â· Sistemes Operatius (SO) [ğŸ ](/index.html)</a>"
editor: visual

execute:
  freeze: auto
  echo: false
---

## QuÃ¨ Ã©s la memÃ²ria virtual? {.smaller}

La **memÃ²ria virtual** Ã©s un mecanisme que permet que els programes sâ€™executin com si disposessin dâ€™un espai dâ€™adreces molt mÃ©s gran que la *MemÃ²ria Principal* real.

:::{.fragment}
Funciona com un sistema de **cache**:

- La **MemÃ²ria Principal (MP)** actua com un cache, perÃ² a diferÃ¨ncia dâ€™un cache no hi ha associativitat ni lÃ­nies mÃºltiples: **la traducciÃ³ Ã©s estrictament per pÃ gina**.
- La **MemÃ²ria SecundÃ ria (MS)** (disc/SSD) Ã©s la memÃ²ria gran perÃ² lenta.
- El SO nomÃ©s mantÃ© en **MP** les pÃ gines que s'estan utilitzant.
:::


:::{.fragment}
Lâ€™objectiu Ã©s mantenir a la **MP** el conjunt de treball del procÃ©s (les pÃ gines usades recentment). Quan el *conjunt resident* â‰ˆ **conjunt de treball** â†’ el rendiment Ã©s Ã²ptim.
:::

:::{.fragment .center-container}
La **MP** Ã©s la cache de la **MS**. Les pÃ gines sÃ³n els blocs. Les fallades de pÃ gina sÃ³n misses de cache.
:::

## CaracterÃ­stiques de la memÃ²ria virtual {.smaller}

- **Incrementa la multiprogramaciÃ³**: cap procÃ©s necessita estar completament a la MP (nomÃ©s les pÃ gines actives).

- **Permet executar programes mÃ©s grans que la MP**: nomÃ©s es carreguen pÃ gines quan cal.

- **Comportament no determinista del temps dâ€™accÃ©s**: una instrucciÃ³ pot trigar nanosegons o milÂ·lisegons segons si es produeix una fallada de pÃ gina.
  
- **Localitat = rendiment**: si el procÃ©s segueix un patrÃ³ de localitat (temporal + espacial), les fallades disminueixen.

- **HiperpaginaciÃ³**: si cap procÃ©s pot mantenir resident el seu conjunt de treball, el sistema entra en un bucle de fallades â†’ rendiment â‰ˆ 0.

:::{.fragment .center-container}
*HiperpaginaciÃ³* = la CPU estÃ  ocupada gestionant fallades, no executant programes.
:::

## PaginaciÃ³ sota demanda {.smaller}

- Les pÃ gines **nomÃ©s es carreguen quan sâ€™hi accedeix per primera vegada.**
- Lâ€™inici del procÃ©s Ã©s *lazy*: **cap pÃ gina Ã©s resident** fins que es referÃ¨ncia.
- Quan es produeix una fallada:

- La MMU genera un trap cap al SO
- El SO decideix on colÂ·locar la pÃ gina
- La pÃ gina es transfereix des del disc
- Lâ€™execuciÃ³ es reprÃ¨n

:::{.fragment .center-container}
Aquest enfocament Ã©s extremadament eficient quan hi ha localitat.
:::

## PaginaciÃ³ anticipada {.smaller}

La idea Ã©s **reduir el nombre futur de fallades** aprofitant la localitat:

- Es carreguen pÃ gines properes a la que ha fallat (per exemple, seqÃ¼encials).
- Pot ser molt Ãºtil en lectures seqÃ¼encials o recorreguts de codis/arrays.
- PerÃ² si la predicciÃ³ Ã©s dolenta â†’ es carrega memÃ²ria innecessÃ ria i empitjora el rendiment.

:::{.fragment}
**Prepaging = precache**:

- Funciona quan hi ha patrons previsibles.
- Fracassa quan hi ha accÃ©s dispers o saltos aleatoris.
:::

## Tractament de la Fallada de PÃ gina {.smaller}

Quan la MMU detecta que una pÃ gina no Ã©s resident (F):

1. **Comprovar si hi ha un marc lliure** (MP).
   - Si nâ€™hi ha, sâ€™hi carrega la pÃ gina F.

2. **Si no hi ha marcs lliures**:
   - Seleccionar una **vÃ­ctima (V)** segons lâ€™algorisme de reemplaÃ§ament.
   - Invalidar l'entrada de V a la taula de pÃ gines.
   - Si V Ã©s dirty, escriure-la al disc.
   - Carregar la pÃ gina F al marc de V.
   - Marcar F com a vÃ lida.
  
:::{.fragment}
Com que carregar una pÃ gina pot trigar milÂ·lisegons, el SO despatxa un altre procÃ©s per no bloquejar la CPU.
:::

## QuÃ¨ Ã©s un TLB? {.smaller}

La **TLB (Translation Lookaside Buffer)** Ã©s una petita memÃ²ria associativa que guarda les traduccions recents dâ€™adreces virtuals â†’ fÃ­siques.

- El seu objectiu Ã©s **accelerar** lâ€™accÃ©s a memÃ²ria.
- Actua com una **cache de la taula de pÃ gines**.
- Si la TLB tÃ© lâ€™entrada que busquem â†’ trobem rÃ pidament el marc fÃ­sic.
- AixÃ² evita consultes lentes a la taula de pÃ gines (que sol estar a memÃ²ria).

:::{.fragment .center-container}
**TLB = cache de traduccions.** Si hi ha encert (*hit*), no cal consultar la taula de pÃ gines.
:::

## TLB Hit vs. TLB Miss {.smaller}

Quan la CPU genera una adreÃ§a virtual:

- **TLB Hit**
  - La TLB contÃ© la traducciÃ³.
  - Lâ€™accÃ©s a memÃ²ria Ã©s rÃ pid (nomÃ©s un accÃ©s real a DRAM).

- **TLB Miss**
  - La TLB **no** contÃ© la traducciÃ³.
  - La MMU consulta la **taula de pÃ gines** a la MP.
  - DesprÃ©s actualitza la TLB amb la nova entrada.
  - Si la PTE (*Page Table Entry*) indica que la pÃ gina **no estÃ  a MP** â†’ es produeix fallada de pÃ gina.

## Per quÃ¨ necessitem una TLB? {.smaller}

Consultar la taula de pÃ gines Ã©s lent perquÃ¨:

- Normalment implica 1 o 2 accessos a memÃ²ria (multinivell).
- A cada accÃ©s sâ€™ha de fer la traducciÃ³ del marc fÃ­sic de la PTE.
- Si fÃ©ssim 2 accessos per cada lectura de memÃ²ria â†’ el sistema seria massa lent.

La TLB permet:

- Reduir la latÃ¨ncia de traducciÃ³.
- Executar programes com si la traducciÃ³ fos *gratis*.
- **Aprofitar la localitat temporal**: sâ€™accedeix repetidament a les mateixes pÃ gines.

:::{.fragment .center-container}
Traduir cada adreÃ§a no pot ser mÃ©s lent que accedir a memÃ²ria.
:::

## AccÃ©s en paralÂ·lel {.smaller}

Els processadors moderns fan lâ€™accÃ©s a TLB i cache en paralÂ·lel, perquÃ¨:

- La part **desplaÃ§ament** de lâ€™adreÃ§a virtual Ã©s la mateixa en lâ€™adreÃ§a fÃ­sica. Permet calcular lâ€™Ã­ndex de la cache abans de tenir la traducciÃ³ completa.

1. La CPU envia lâ€™adreÃ§a virtual.
2. La TLB busca la traducciÃ³ mentre la cache comenÃ§a a buscar per lâ€™Ã­ndex.
3. Si la TLB fa hit, sâ€™omple la resta de lâ€™adreÃ§a fÃ­sica i sâ€™acaba la cerca.
4. AccÃ©s molt rÃ pid, sense esperes addicionals.

:::{.fragment .center-container}
**TLB + Cache** treballen en paralÂ·lel per reduir el temps dâ€™accÃ©s efectiu.
:::

## TEA: Temps Efectiu d'AccÃ©s (*sense fallades*) {.smaller}

El Temps Efectiu dâ€™AccÃ©s (TEA) Ã©s el temps mig per accedir a memÃ²ria tenint en compte:

- Si la TLB fa hit (accÃ©s rÃ pid)= $\text{TEA hit}â€‹=t_{TLB}â€‹+t_{MP}â€‹$

- Si la TLB fa miss (cal consultar la taula de pÃ gines a la MP)= $\text{TEA miss}â€‹=t_{TLB}â€‹+2\cdot t_{MP}â€‹$

:::{.fragment .center-container}
$$TEA = (p \cdot \text{TEA hit}) + ((1-p) \cdot \text{TEA miss})$$
:::

:::{.fragment}
**On**: $t_{TLB}$ = temps dâ€™accÃ©s a la TLB, $t_{MP}$ = temps dâ€™accÃ©s a la MemÃ²ria Principal, $p$ = taxa dâ€™encerts de la TLB (TLB hit rate).
:::

:::{.fragment .center-container}
Com mÃ©s alta Ã©s la taxa dâ€™encerts de la TLB, mÃ©s rÃ pid Ã©s lâ€™accÃ©s efectiu.
:::

## Temps MS->MP  {.smaller}

Els discs sÃ³n el dispositiu de paginaciÃ³ tradicional mÃ©s utilitzat. Comparats amb la MemÃ²ria Principal, els discs (sobretot els HDD) sÃ³n moltes orders de magnitud mÃ©s lents. Quan es carrega una pÃ gina de la MemÃ²ria SecundÃ ria (MS) a la MemÃ²ria Principal (MP), el temps total ve determinat per:

- **Temps de cerca $T_{c}$**: Temps necessari perquÃ¨ les capÃ§als mecÃ niques es colÂ·loquin sobre el cilindre correcte.
- **Temps de latÃ¨ncia $T_{l}$**: Temps dâ€™espera fins que el sector de la pÃ gina passa sota la capÃ§al (rotaciÃ³ del disc).
- **Temps de transferÃ¨ncia $T_{t}$**: Temps necessari per llegir la pÃ gina completa i enviar-la cap a la MP.

:::{.fragment}
$$T_{MS-MP} = T_{c} + T_{l} + T_{t}$$
:::

## Ordres de magnitud {.smaller}

- **Temps de cerca $T_{c}$**: DepÃ¨n del disseny fÃ­sic del disc i de lâ€™algorisme dâ€™assignaciÃ³ de sectors. Sol ser de lâ€™ordre dels milÂ·lisegons (ms).
- **Temps de latÃ¨ncia $T_{l}$**: DepÃ¨n de la velocitat de rotaciÃ³ del disc. Sol ser de lâ€™ordre dels milÂ·lisegons (ms).
- **Temps de transferÃ¨ncia $T_{t}$**: DepÃ¨n de lâ€™amplada de banda del disc i de la mida de la pÃ gina. Sol ser de lâ€™ordre dels milÂ·lisegons (ms).

:::{.fragment}
Un SSD/NVMe redueix significativament aquests temps (ordre $\mu s$, no tÃ© $T_{c}$ ni $T_{l}$), perÃ² encara Ã©s molt mÃ©s lent que la MP.
:::

:::{.fragment .center-container}
Una fallada de pÃ gina pot ser 100.000Ã—-1000Ã— mÃ©s lenta que un accÃ©s normal! Encara que $P$ sigui molt petit, el cost dâ€™una fallada de pÃ gina Ã©s tan elevat que pot disparar dramÃ ticament el TEA.
:::

## TEA *amb fallades*  {.smaller}

$$TEA = [ (1-p) \cdot (T_{a})] + [p \cdot (T_{fp})]$$

on:

- $p$ = probabilitat de fallada de pÃ gina.
- $T_{a}$ = temps dâ€™accÃ©s quan no hi ha fallada de pÃ gina (TLB hit/miss + MP).
- $T_{fp}$ = temps dâ€™accÃ©s quan hi ha fallada de pÃ gina.
  - $MS-MP$ = temps per portar la pÃ gina des de MS a MP.
  - temps de reemplaÃ§ament (si hi ha vÃ­ctima)
  - temps d'actualitzar la taula de pagines.
  - temps de rependrÃ¨ la execuciÃ³.


## Ex01: TEA amb PaginaciÃ³ {.smaller}

- Disposem dâ€™un disc que gira a $7.500 rev/min$. 
- Aquest disc tÃ© un temps de cerca de $2ms$ i transfereix $100.000$ paraules/s. 
- La probabilitat de fallada Ã©s de $P=0,25$ 
- La mida dâ€™una pÃ gina Ã©s $1.000$ paraules. 
- Els sistema de gestiÃ³ de memÃ²ria Ã©s PaginaciÃ³ (la taula de pÃ gines sâ€™implementa en MP) 
- El Temps dâ€™accÃ©s ($T_{a}$) a MP Ã©s $4 \mu s$. 
- Assumeix per simplicitat que no fem servir TLB.
- Calcular $TEA$.

## Ex01: TEA amb PaginaciÃ³(I) {.smaller}

$$T_{a} = 4 \mu s = 4 \cdot 10^{-6} s$$

:::{.fragment}
$$ T_{c} = 2ms = 2 \cdot 10^{-3}s$$
:::

:::{.fragment}
$$T_{l} = 7500 \frac{rev}{min} \cdot \frac{1 min}{60 seg} = 125 \frac{rev}{seg} \rightarrow T_{l} = \frac{1}{2} \cdot \frac{1}{125}s = 4 \cdot 10^{-3} s$$
:::

:::{.fragment}
$$T_{t} = 100.000 \frac{paraules}{segon} \cdot \frac{1 pagina}{1.000 paraules} = 100 \frac{pagines}{segon} \rightarrow T_{t} = 10^{-2} s = 10 \cdot 10^{-3} s$$
:::

:::{.fragment}
$$T_{MP-MS} = T_{c} + T_{l} + T_{t} = 2 \cdot 10^{-3} + 4 \cdot 10^{-3} + 10 \cdot 10^{-3} = 16 \cdot 10^{-3}s$$
:::

:::{.fragment .center-container}
La relaciÃ³ $\frac{1}{2}$ Ã©s un assumpciÃ³ comuna en el context dels discos durs. Fa referencia al temps mitjÃ  que tarda el disc a girar per situar-se a la pista/cilindre desitjat per fer una operaciÃ³ de lectura o escriptura.
:::

## Ex01: TEA amb PaginaciÃ³(II) {.smaller}

$$TEA = [(1-P) \cdot (T_{a})] + [P \cdot (T_{fp})]$$

:::{.fragment}
Com el sistema de gestiÃ³ de memÃ²ria Ã©s PaginaciÃ³:

1. Si no hi ha fallada de pÃ gina, el temps d'accÃ©s a *MemÃ²ria Principal* Ã©s $2 \cdot T_{a}$. Ja que s'ha d'accedir a la taula de pÃ gines i a la pÃ gina.

2. En cas de fallada de pÃ gina, el temps d'accÃ©s a *MemÃ²ria Principal* Ã©s $T_{MP-MS} + 3 \cdot T_{a}$. Ja que s'ha d'accedir a la taula de pÃ gines, desprÃ©s s'ha de carregar la pÃ gina a *MemÃ²ria Principal*, accedir a la pÃ gina i finalment accedir a la taula de pÃ gines per marcar la pÃ gina com a vÃ lida (**actualitzaciÃ³ de la taula**).
:::

:::{.fragment .center-container}
$$TEA = [(1-P) \cdot (2 \cdot T_{a})] + [P \cdot (T_{MP-MS} + 3 \cdot T_{a})]$$
$$TEA = [(1-0,25) \cdot (2 \cdot 4 \cdot 10^{-6})] + [0,25 \cdot (16 \cdot 10^{-3} + 3 \cdot 4 \cdot 10^{-6})]$$
$$TEA = 4,009 \; ms$$
:::

## Ex02: TEA & SegmentaciÃ³ Paginada {.smaller} 

Suposeu que tenim un sistema amb memÃ²ria virtual (del tipus paginaciÃ³ sota demanda). El sistema de gestiÃ³ de memÃ²ria Ã©s **SegmentaciÃ³ Paginada**. Totes les taules (de segments i de pÃ gines) sâ€™implementen en M.P (MemÃ²ria Principal). Les pÃ gines tenen 1.000 paraules. El dispositiu de paginaciÃ³ Ã©s un disc dur amb un temps de cerca mig de $10 ms$. El disc dur gira a 7.200 revolucions per minut i transfereix 1.000.000 paraules per segon. Assumeix que el TLB no sâ€™utilitza.

:::{.fragment}
D'entre tots els accessos, el 20\% dels mateixos es realitzen a pÃ gines carregades en M.P. Quan es produeix una fallada de pÃ gina, el 60% de les vegades es reemplaÃ§a una pÃ gina. El 70\% de les vegades, la pÃ gina a reemplaÃ§ar ha estat accedida solament en mode lectura. Quan es produeix una fallada de pÃ gina, l'actualitzaciÃ³ de les taules de pÃ gines dels processos triga $1 \mu s$. El temps dâ€™accÃ©s a memÃ²ria Ã©s $2 \mu s$.
:::

:::{.fragment .center-container}
Quin Ã©s el temps efectius d'accÃ©s (TEA) a M.P.?
:::

## Ex02: TEA & Seg.Pag (I) {.smaller} 

Calculem els diferents temps:

- $T_c = 10 ms = 10 \cdot 10^{-3} s$
- $T_l = 7200 \frac{rev}{min} \cdot \frac{1 min}{60 seg} = 120 \frac{rev}{seg} \rightarrow T_l = \frac{1}{2} \cdot \frac{1}{120} s = 4,166 \cdot 10^{-3} s \approx 4 \cdot 10^{-3} s$
- $T_t = 1.000.000 \frac{paraules}{segon} \cdot \frac{1 pagina}{1.000 paraules} = 1.000 \frac{pagines}{segon} \rightarrow T_t = 10^{-3} s$
- $T_{MP-MS} = T_c + T_l + T_t = 10 \cdot 10^{-3} + 4 \cdot 10^{-3} + 10^{-3} = 15 \cdot 10^{-3} s$
- $T_a = 2 \mu s = 2 \cdot 10^{-6} s = 0,002 \cdot  10^{-3} s$
- $T_{Ac-Tau} = 1 \mu s = 1 \cdot 10^{-6} s = 0,001 \cdot 10^{-3} s$

## Ex02: TEA & Seg.Pag (II) {.smaller}

- **20\% de les vegades**: (no hi ha fallada de pÃ gina).
- **80\% de les vegades**: (hi ha fallada de pÃ gina).
  - *60\% de les vegades*: (hi ha fallada de pÃ gina i es reemplaÃ§a una pÃ gina). **30\% de les vegades (CelÂ·la vÃ­citma modificada)** i el **70\% de les vegades: (CelÂ·la vÃ­ctima no modificada)**
  - *40\% de les vegades*: (hi ha fallada de pÃ gina i no es reemplaÃ§a una pÃ gina).

:::{.fragment}
\begin{equation*}
\begin{split}
    TEA = & \, 0.2 \cdot (\text{Temps NO fallada}) + 0.8 \cdot (\text{Temps fallada}) \\
         = & \, 0.2 \cdot (\text{Temps NO fallada}) \\
         & + 0.8 \cdot \left[ 0.6 \cdot (\text{Temps reemplaÃ§ament}) + 0.4 \cdot (\text{Temps sense reemplaÃ§ament}) \right]
\end{split}
\end{equation*}
:::

:::{.fragment}
\begin{align*}
    \text{Temps reemplaÃ§ament} &= (0.3 \cdot \text{Temps intercanvi celÂ·la/pÃ gina (MP - MS)}) \\
                                &+ (0.7 \cdot \text{Temps moure pÃ gina (MS a MP)}) \\
\end{align*}
:::


## Ex02: TEA & Seg.Pag (III) {.smaller}

$$ \text{Temps NO fallada} = 3 \cdot T_a $$

- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines.
- 1 accÃ©s a la celÂ·la.

:::{.fragment .center-container}
$$ TEA = \frac{20}{100} \cdot (3 \cdot T_a) + \frac{80}{100} \cdot \text{Temps fallada} $$
:::


## Ex02: TEA & Seg.Pag (IV) {.smaller}

$$ \text{Temps fallada} = \frac{60}{100} \cdot \text{Temps reemplaÃ§ament} +  \frac{40}{100}  \cdot \text{Temps sense reemplaÃ§ament} $$

:::{.fragment}
*On*: $\text{Temps sense reemplaÃ§ament} = T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau}$
:::

- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines. -> *PÃ gina no a MP*
- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines.
- 1 accÃ©s a la celÂ·la.
- Portar la pÃ gina de MS a MP.
- Actualitzar les taules.

## Ex02: TEA & Seg.Pag (V) {.smaller}

\begin{equation*}
\begin{split}
    TEA = &\frac{20}{100} \cdot (3 \cdot T_a) \\
          &+ \frac{80}{100} \cdot \left[ \frac{60}{100} \cdot \text{Temps reemplaÃ§ament} +  \frac{40}{100} \cdot \left( T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau} \right) \right]
\end{split}
\end{equation*}

## Ex02: TEA & Seg.Pag (IV) {.smaller}

$$ \text{Temps reemplaÃ§ament} = \frac{30}{100} \cdot \text{Temps Modificada} + \frac{70}{100} \cdot \text{Temps No Modificada} $$

:::{.fragment}
*On*: $\text{Temps No Modificada} = T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau}$
:::

- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines. -> *PÃ gina no a MP*
- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines.
- 1 accÃ©s a la celÂ·la.
- Portar la pÃ gina de MS a MP.
- Actualitzar les taules.
  
## Ex02: TEA & Seg.Pag (V) {.smaller}

$$ \text{Temps reemplaÃ§ament} = \frac{30}{100} \cdot \text{Temps Modificada} + \frac{70}{100} \cdot \text{Temps No Modificada} $$

:::{.fragment}
*On*: $\text{Temps Modificada} = 2 \cdot T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau}$
:::

- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines. [PÃ gina no a MP]{.alert}
- 1 accÃ©s a la taula de segments.
- 1 accÃ©s a la taula de pÃ gines.
- 1 accÃ©s a la celÂ·la.
- Guardar a MS la celÂ·la vÃ­ctima modificada.
- Portar la pÃ gina de MS a MP.
- Actualitzar les taules.



## Ex02: TEA & Seg.Pag (VI) {.smaller}

\begin{equation*}
\begin{split}
    TEA = &\frac{20}{100} \cdot (3 \cdot T_a) \\
          &+ \frac{80}{100} \cdot \left[ \begin{aligned}
                &\frac{40}{100} \cdot \left( T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau} \right) \\
                &+ \frac{60}{100} \cdot \left[ \begin{aligned}
                        &\frac{30}{100} \cdot \left( 2 \cdot T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau} \right) \\
                        &+ \frac{70}{100} \cdot \left( T_{MP-MS} + 5 \cdot T_a + T_{Ac-Tau} \right)
                   \end{aligned} \right]
              \end{aligned} \right]
\end{split}
\end{equation*}

$$TEA = 14,17 \; ms$$

## GestiÃ³ de marcs {.smaller}

La gestiÃ³ de marcs (*frames*) determina quÃ¨ sâ€™assigna a cada procÃ©s i quÃ¨ sâ€™expulsa quan cal alliberar espai a la MemÃ²ria Principal (MP).

1. **Algorismes d'assignaciÃ³**: Determinen quines celÂ·les de la *MemÃ²ria Principal* sÃ³n assignades a cada procÃ©s.
   - AssignaciÃ³ Local.
   - AssignaciÃ³ Global.

2. **Algorismes de reemplaÃ§ament**: Determinen quines celÂ·les de la *MemÃ²ria Principal* sÃ³n substituÃ¯des quan es produeix una fallada de pÃ gina i no hi ha cap celÂ·la lliure.
   - Ã’ptim.
   - FIFO.
   - Segona Oportunitat.
   - LRU.
   - Buffering de pÃ gines.
  

## AssignaciÃ³ local {.smaller}

- Aquest algorisme assigna a cada procÃ©s un **nombre fix de celÂ·les** (*marcs*) a la MemÃ²ria Principal.
- Davant dâ€™una fallada de pÃ gina, **nomÃ©s es poden substituir pÃ gines del mateix procÃ©s que lâ€™ha provocada**.
- Evita que un procÃ©s **monopolitzin totes les celÂ·les de la MP**, mantenint un cert aÃ¯llament entre processos.
- Aquesta tÃ¨cnica **limita lâ€™impacte de la substituciÃ³**: cap procÃ©s pot expulsar pÃ gines dâ€™un altre, reduint interferÃ¨ncies.

## Min. nÂº de celÂ·les per procÃ©s? {.smaller}

Cal garantir que qualsevol instrucciÃ³ que el procÃ©s executi pot ser resolta amb les pÃ gines que tÃ© assignades.

El nombre mÃ­nim de celÂ·les dependrÃ  de:

- El format de la instrucciÃ³ (quantes paraules ocupa).
- El tipus dâ€™adreÃ§ament dels operands:
  - Immediat: 0 celÂ·les extra.
  - Directe: 1 celÂ·la.
  - Indirecte: 2 celÂ·les (perquÃ¨ cal llegir l'adreÃ§a i desprÃ©s accedir-hi).
  - Indexat: 1 celÂ·la addicional.
- Lâ€™accÃ©s a la celÂ·la on sâ€™escriu el resultat.

:::{.fragment .center-container}
Aquest mÃ­nim determina el nombre de marcs que cal assignar al procÃ©s perquÃ¨ pugui executar qualsevol instrucciÃ³ sense fallades permanents.
:::

## Ex03: AssignaciÃ³ local â€“ CÃ lcul del mÃ­nim nombre de celÂ·les {.smaller}

Suposeu que el format dâ€™una instrucciÃ³ ocupa **dues paraules** (mida paraula = 1 Byte):

- **Paraula 1** = OPCODE + **Paraula 2** = OPERANDS, que contÃ© els codis de mode dâ€™adreÃ§ament dels tres operands (OP1, OP2, RES).
- Els valors o adreces referenciades pels operands no formen part de la instrucciÃ³, sinÃ³ que resideixen a celÂ·les de memÃ²ria independents.

:::{.fragment .center-container}
Quin Ã©s el mÃ­nim nombre de celÂ·les que cal assignar a un procÃ©s? *Suposem que OP1 i OP2 sÃ³n operands dâ€™adreÃ§ament indirecte i RES Ã©s directe.*
:::

:::{.fragment}
- OP1 (indirecte): cal llegir 2 celÂ·les
- OP2 (indirecte): cal llegir 2 celÂ·les
- RES (directe): cal una 1 celÂ·la
- Total mÃ­nim = 2 (instrucciÃ³) + 2 + 2 + 1 = 7 celÂ·les de MP
:::

## AssignaciÃ³ global {.smaller}

En lâ€™assignaciÃ³ global, els marcs de la MemÃ²ria Principal (MP) es distribueixen entre tots els processos considerant la visiÃ³ global del sistema. A diferÃ¨ncia de lâ€™assignaciÃ³ local, en aquest model:

- El sistema pot redistribuir marcs dinÃ micament entre processos
- Un procÃ©s pot expulsar pÃ gines dâ€™altres processos. *AixÃ² nomÃ©s passa quan el sistema utilitza reemplaÃ§ament global. Pots tenir assignaciÃ³ global + reemplaÃ§ament local o viceversa.*

:::{.fragment}
Hi ha dues estratÃ¨gies habituals:

1. **AssignaciÃ³ IgualitÃ ria**: Cada procÃ©s rep un nombre igual de marcs, independentment de les seves necessitats o comportament.
2. **AssignaciÃ³ Proporcional**: Els marcs es distribueixen segons les necessitats o la mida de cada procÃ©s, permetent que processos mÃ©s grans tinguin mÃ©s marcs.
:::

## Ex04: IgualitÃ ria vs Proporcional {.smaller}

Suposeu que disposem dâ€™una MP de 8 celÂ·les. Si tenim 3 processos, amb uns requeriments de memÃ²ria de P1 (6 celÂ·les), P2 (3 celÂ·les) i P3 (2 celÂ·les). Quina serÃ  l'assignaciÃ³ de MemÃ²ria segons els algorismes d'AssignaciÃ³ IgualitÃ ria i Proporcional?

- **AssignaciÃ³ IgualitÃ ria**: Cada procÃ©s tÃ© assignades $\frac{8}{3} = 2,66$ celÂ·les de MP. Per tant, el procÃ©s P1 tÃ© assignades 2 celÂ·les de MP, el procÃ©s P2 tÃ© assignades 2 celÂ·les de MP i el procÃ©s P3 tÃ© assignades 2 celÂ·les de MP. En total hi ha 2 celÂ·les lliures.

- **AssignaciÃ³ Proporcional**:
  - ProcÃ©s P1: $\frac{6 \cdot 8}{6+3+2} = 4,36$ celÂ·les de MP (4 celÂ·les de MP).
  - ProcÃ©s P2: $\frac{3 \cdot 8}{6+3+2} = 2,18$ celÂ·les de MP (2 celÂ·les de MP).
  - ProcÃ©s P3: $\frac{2 \cdot 8}{6+3+2} = 1,09$ celÂ·les de MP (1 celÂ·la de MP).
  - En total hi ha 1 celÂ·la lliure.

## RetenciÃ³ de pÃ gines {.smaller}

No totes les pÃ gines residents a MemÃ²ria es poden reemplaÃ§ar. Hi ha pÃ gines que no es poden reemplaÃ§ar perquÃ¨ sÃ³n necessÃ ries, com per exemple les pÃ gines que contenen les funcions del sistema operatiu. 

A mÃ©s a mÃ©s, en sistemes linux, existeix la crida a sistema *mlock* que permet fixar una pÃ gina a la *MemÃ²ria Principal*.

```c
#include <sys/mman.h>
int mlock(const void *addr, size_t len);
```

## ReemplaÃ§ament de pÃ gines - Ã’ptim {.smaller}

- Lâ€™algorisme Ã’ptim (OPT) substitueix la pÃ gina que no tornarÃ  a ser necessÃ ria durant mÃ©s temps en el futur.
  
- Ã‰s la polÃ­tica que minimitza el nombre total de fallades de pÃ gina, perÃ² no es pot implementar en temps real, ja que requereix conÃ¨ixer lâ€™accÃ©s futur. *Sâ€™utilitza com a referÃ¨ncia teÃ²rica (llindar inferior)*.

- Mirar endavant en la seqÃ¼Ã¨ncia dâ€™accÃ©s -> expulsar la pÃ gina amb la prÃ²xima referÃ¨ncia mÃ©s llunyana (o que no es torna a referenciar).

:::{.fragment .center-container}
Regla *farthest next use*, i si totes sÃ³n infinits (*no es tornen a usar*) el resultat depÃ¨n de la tria arbitrÃ ria â€”> totes les opcions sÃ³n igualment Ã²ptimes en aquell punt.
:::


## Ex: ReemplaÃ§ Ã’ptim {.smaller}

:::{.center-container}
Assumeix 3 marcs i la segÃ¼ent seqÃ¼Ã¨ncia de referÃ¨ncies a pÃ gines:
0 â†’ 7 â†’ 5 â†’ 8 â†’ 10 â†’ 12 â†’ 0 â†’ 10 â†’ 8 â†’ 5 â†’ 9 â†’ 7
:::

:::{.callout-warning title="Funcionament"}

| Pas | ReferÃ¨ncia | Marcs |                                       Page fault?                                      |
| --: | :--------: | :-----------------: | :------------------------------------------------------------------------------------: |
|   0 |      0     |      [0, â€“, â€“]      |                                         SÃ­ (1)                                         |
|   1 |      7     |      [0, 7, â€“]      |                                         SÃ­ (2)                                         |
|   2 |      5     |      [0, 7, 5]      |                                         SÃ­ (3)                                         |
|   3 |      8     |      [0, 8, 5]      |                   SÃ­ (4) â€” reemplaÃ§a 7 (proper Ãºs futur a posiciÃ³ 11)                  |
|   4 |     10     |      [0, 8, 10]     |                   SÃ­ (5) â€” reemplaÃ§a 5 (proper Ãºs futur a posiciÃ³ 9)                   |
|   5 |     12     |     [0, 12, 10]     |                   SÃ­ (6) â€” reemplaÃ§a 8 (proper Ãºs futur a posiciÃ³ 8)                   |
|   6 |      0     |     [0, 12, 10]     |                                        No (hit)                                        |
|   7 |     10     |     [0, 12, 10]     |                                        No (hit)                                        |
|   8 |      8     |      [0, 8, 10]     | SÃ­ (7) â€” totes les altres pÃ gines no tornen a aparÃ¨ixer; escollim una (per exemple 12) |
|   9 |      5     |      [5, 8, 10]     |                 SÃ­ (8) â€” escollim expulsar 0 (no apareix mÃ©s endavant)                 |
|  10 |      9     |      [9, 8, 10]     |                       SÃ­ (9) â€” expulsar 5 (no torna a aparÃ¨ixer)                       |
|  11 |      7     |      [7, 8, 10]     |                                  SÃ­ (10) â€” expulsar 9                                  |

:::



## ReemplaÃ§ament de pÃ gines - FIFO {.smaller}

- L'algorisme FIFO Ã©s un algorisme de reemplaÃ§ament de pÃ gines que substitueix la pÃ gina que ha estat a la *MemÃ²ria Principal* durant mÃ©s temps.

- FIFO no utilitza informaciÃ³ del futur. Expulsa sempre la pÃ gina mÃ©s antiga.

- Ã‰s senzill d'implementar, perÃ² pot portar a un rendiment subÃ²ptim en alguns casos (ex: *Anomalies de Belady*).

## Ex: ReemplaÃ§ FIFO {.smaller}

:::{.center-container}
Assumeix 3 marcs i la segÃ¼ent seqÃ¼Ã¨ncia de referÃ¨ncies a pÃ gines:
0 â†’ 7 â†’ 5 â†’ 8 â†’ 10 â†’ 12 â†’ 0 â†’ 10 â†’ 8 â†’ 5 â†’ 9 â†’ 7
:::

:::{.callout-warning title="Funcionament"}

| Ref | F1 | F2 | F3 | Fault | Expulsa |
| --: | -- | -- | -- | :---: | :-----: |
|   0 | 0  | â€“  | â€“  |   âœ“   |    â€“    |
|   7 | 0  | 7  | â€“  |   âœ“   |    â€“    |
|   5 | 0  | 7  | 5  |   âœ“   |    â€“    |
|   8 | 8  | 7  | 5  |   âœ“   |    0    |
|  10 | 8  | 10 | 5  |   âœ“   |    7    |
|  12 | 8  | 10 | 12 |   âœ“   |    5    |
|   0 | 0  | 10 | 12 |   âœ“   |    8    |
|  10 | 0  | 10 | 12 |   âœ—   |    â€“    |
|   8 | 0  | 8  | 12 |   âœ“   |    10   |
|   5 | 0  | 8  | 5  |   âœ“   |    12   |
|   9 | 9  | 8  | 5  |   âœ“   |    0    |
|   7 | 9  | 7  | 5  |   âœ“   |    8    |



:::

## RemplaÃ§ament de pÃ gines - LRU {.smaller}

- L'algorisme LRU (Least Recently Used) substitueix la pÃ gina que no ha estat utilitzada durant el perÃ­ode de temps mÃ©s llarg.

- El funcionament bÃ sic consisteix a mantenir un registre de l'ordre d'Ãºs de les pÃ gines i expulsar la que fa mÃ©s temps que no s'utilitza.

- Ã‰s una aproximaciÃ³ prÃ ctica a Ã“ptim quan les referÃ¨ncies presenten localitat temporal.

- No es pot implementar de manera eficient sense suport de maquinari (*cadenes, timestamps, etc.*).

## Ex: ReemplaÃ§ LRU {.smaller}

:::{.center-container}
Assumeix 3 marcs i la segÃ¼ent seqÃ¼Ã¨ncia de referÃ¨ncies a pÃ gines:
0 â†’ 7 â†’ 5 â†’ 8 â†’ 10 â†’ 12 â†’ 0 â†’ 10 â†’ 8 â†’ 5 â†’ 9 â†’ 7
:::

:::{.callout-warning title="Funcionament"}

| Ref | F1 | F2 | F3 | Fault | Expulsa (LRU) |
| --: | -- | -- | -- | :---: | :-----------: |
|   0 | 0  | â€“  | â€“  |   âœ“   |       â€“       |
|   7 | 0  | 7  | â€“  |   âœ“   |       â€“       |
|   5 | 0  | 7  | 5  |   âœ“   |       â€“       |
|   8 | 8  | 7  | 5  |   âœ“   |       0       |
|  10 | 8  | 10 | 5  |   âœ“   |       7       |
|  12 | 8  | 10 | 12 |   âœ“   |       5       |
|   0 | 0  | 10 | 12 |   âœ“   |       8       |
|  10 | 0  | 10 | 12 |   âœ—   |       â€“       |
|   8 | 0  | 10 | 8  |   âœ“   |       12      |
|   5 | 5  | 10 | 8  |   âœ“   |       0       |
|   9 | 5  | 9  | 8  |   âœ“   |       10      |
|   7 | 5  | 9  | 7  |   âœ“   |       8       |


:::


## ReemplaÃ§ament de pÃ gines - 2Âª Oportunitat {.smaller}

La Segona Oportunitat Ã©s una millora de **FIFO** que utilitza el bit de referÃ¨ncia (*R*) per evitar expulsar pÃ gines que han estat utilitzades recentment.

1. FIFO selecciona la pÃ gina mÃ©s antiga.
2. Segona Oportunitat comprova el bit R:
   - R = 0 â†’ la pÃ gina no ha estat usada recentment â†’ sâ€™expulsa.
   - R = 1 â†’ la pÃ gina ha estat usada â†’ 
     - Sâ€™ajusta R = 0
     - La pÃ gina es mou al final de la cua (rep una segona oportunitat).
3. Es continua avanÃ§ant circularment fins trobar una amb R = 0.

:::{.fragment .center-container}
La idea Ã©s aproximar el comportament de LRU sense haver dâ€™actualitzar estructures costoses.
:::

## Ex: ReemplaÃ§ 2Âª Oportunitat {.smaller}

:::{.center-container}
Assumeix 3 marcs i 0 â†’ 7 â†’ 5 â†’ 8 â†’ 10 â†’ 12 â†’ 0 â†’ 10 â†’ 8 â†’ 5 â†’ 9 â†’ 7
:::

:::{.callout-warning title="Funcionament"}

| Ref | F1    | F2     | F3    | Fault | VÃ­ctima |
| --: | ----- | ------ | ----- | :---: | :-----: |
|   0 | â†’0(1) | â€“      | â€“     |   âœ“   |    â€“    |
|   7 | 0(1)  | â†’7(1)  | â€“     |   âœ“   |    â€“    |
|   5 | 0(1)  | 7(1)   | â†’5(1) |   âœ“   |    â€“    |
|   8 | â†’0(0) | 7(0)   | 5(0)  |   âœ“   |    0    |
|  10 | 8(1)  | â†’7(0)  | 5(0)  |   âœ“   |    7    |
|  12 | 8(1)  | 10(1)  | â†’5(0) |   âœ“   |    5    |
|   0 | â†’8(0) | 10(0)  | 12(0) |   âœ“   |    8    |
|  10 | 0(1)  | â†’10(1) | 12(0) |   âœ—   |    â€“    |
|   8 | â†’0(0) | 10(0)  | 8(1)  |   âœ“   |    12   |
|   5 | â†’0(0) | 10(0)  | 8(1)  |   âœ“   |    0    |
|   9 | 5(0)  | â†’10(0) | 8(0)  |   âœ“   |    10   |
|   7 | 5(0)  | 9(1)   | â†’8(0) |   âœ“   |    8    |

:::



## Algorisme de ReemplaÃ§ament â€“ Clock AvanÃ§at (WSClock) {.smaller}

El WSClock (Working Set Clock) Ã©s una millora del 2Âª Oportunitat que incorpora:

- Bit de referÃ¨ncia (R)
- Bit de modificaciÃ³ (M)
- Temps de lâ€™Ãºltim Ãºs (timestamp)
- Conceptes del conjunt de treball (working set)

:::{.fragment}
Lâ€™objectiu Ã©s expulsar la millor vÃ­ctima possible:
pÃ gina poc usada, preferiblement no modificada, i fora del seu conjunt de treball.
:::

## Funcionament del WSClock {.smaller}

- El punter Clock recorre circularment totes les pÃ gines.
- Per a cada pÃ gina, considera 3 criteris:
  1. $R = 1$ â†’ sâ€™ha utilitzat recentment â†’ es posa R = 0 i es continua.
  2. $R = 0$ i $M = 0$ â†’ excelÂ·lent candidata per ser expulsada.
  3. $R = 0$ i $M = 1$ â†’ Ã©s bona candidata, perÃ² cal escriure-la al disc â†’ es marca per write-back i es continua.
- Si cap pÃ gina compleix les condicions, sâ€™accepta la millor candidata trobada durant el recorregut.

:::{.fragment .center-container}
WSClock â‰ˆ 2Âª Oportunitat + heurÃ­stica del conjunt de treball â‡’ Millor rendiment i menys E/S al disc.
:::

## AnÃ lisi del WSClock {.smaller}

- Redueix  les escriptures al disc
- NomÃ©s expulsa pÃ gines modificades si cal.
- Evita expulsar pÃ gines del conjunt de treball
- Redueix la hiperpaginaciÃ³ â†’ millor TEA.
- LRU es molt car dâ€™implementar en maquinari; WSClock Ã©s barat.
- Algorisme utilitzat en molts sistemes operatius reals com Linux i Windows.


## Ex05: Fallades {.smaller}

Disposem dâ€™una memÃ²ria amb una mida de 4 celÂ·les. Un programa ha realitzat la seqÃ¼Ã¨ncia de referÃ¨ncies a les 19 pÃ gines segÃ¼ent: 

:::{.center-container}
4 â†’ 3 â†’ 2 â†’ 1 â†’ 0 â†’ 1 â†’ 0 â†’ 2 â†’ 3 â†’ 4 â†’ 5 â†’ 6 â†’ 7 â†’ 8 â†’ 1 â†’ 5 â†’ 3 â†’ 4 â†’ 5
:::

- Quantes fallades de pÃ gina es produeixen amb lâ€™algorisme FIFO/LRU/2Âª Oportunitat i assignaciÃ³ global de celÂ·les?
- Quina ha estat la tassa de fallades de pÃ gina?

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/1.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/2.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/3.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/4.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/5.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/6.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/7.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/8.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/9.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/10.png)

## Ex05: FIFO - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_FIFO/11.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/1.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/2.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/3.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/4.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/5.png)

## Ex05: LRU - Fallades {.smaller}-

![](../figures/slides/06-mem/virtual/exercici_lru/6.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/7.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/8.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/9.png)

## Ex05: LRU - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_lru/10.png)

## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/1.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/2.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}
![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/3.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/4.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/5.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/6.png)

## ## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/6.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/7.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}
![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/8.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/9.png)

## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/10.png)


## Ex05: 2Âª Oportunitat - Fallades {.smaller}

![](../figures/slides/06-mem/virtual/exercici_2onOportunitat/11.png)


## AnÃ²malies de Belady {.smaller}

Una anomalia de Belady es produeix quan un algorisme de reemplaÃ§ament *com FIFO* tÃ© mÃ©s fallades de pÃ gina quan augmentem el nombre de marcs.

:::{.fragment}
**Ã‰s contraintuÃ¯tiu** -> mÃ©s memÃ²ria hauria de significar menys fallades, perÃ² amb alguns algorismes aixÃ² no Ã©s cert.
:::

:::{.fragment}
Per exemple, amb la seqÃ¼Ã¨ncia segÃ¼ent: 1 â†’ 2 â†’ 3 â†’ 4 â†’ 1 â†’ 2 â†’ 5 â†’ 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5 i l'algorisme FIFO:

- Si tenim 3 marcs, es produeixen 9 fallades de pÃ gina.
- Si tenim 4 marcs, es produeixen 10 fallades de pÃ gina.
:::

:::{.fragment .center-container}
FIFO pot empitjorar quan augmentem els marcs.
Ã‰s lâ€™Ãºnic algorisme clÃ ssic on apareix aquesta anomalia.
:::

## Ex06: AnÃ²malies de Belady {.smaller}

:::{.center-container}
1 â†’ 2 â†’ 3 â†’ 4 â†’ 1 â†’ 2 â†’ 5 â†’ 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5 
:::

::: columns
::: {.column width="45%"}

:::{.callout-note title="3 marcs"}
| T | C1 | C2 | C3 | Falla? |
| - | -- | -- | -- | ------ |
| 1 | 1  | â€“  | â€“  | âœ”      |
| 2 | 1  | 2  | â€“  | âœ”      |
| 3 | 1  | 2  | 3  | âœ”      |
| 4 | 4  | 2  | 3  | âœ”      |
| 1 | 4  | 1  | 3  | âœ”      |
| 2 | 4  | 1  | 2  | âœ”      |
| 5 | 5  | 1  | 2  | âœ”      |
| 1 | 5  | 1  | 2  | âœ˜      |
| 2 | 5  | 1  | 2  | âœ˜      |
| 3 | 5  | 3  | 2  | âœ”      |
| 4 | 5  | 3  | 4  | âœ”      |
| 5 | 5  | 3  | 4  | âœ˜      |
:::

:::
::: {.column width="45%"}

:::{.callout-warning title="4 marcs"}
| T   | C1 | C2 | C3 | C4 | Falla? |
| --- | -- | -- | -- | -- | ------ |
| 1   | 1  | â€“  | â€“  | â€“  | âœ”      |
| 2   | 1  | 2  | â€“  | â€“  | âœ”      |
| 3   | 1  | 2  | 3  | â€“  | âœ”      |
| 4   | 1  | 2  | 3  | 4  | âœ”      |
| 1   | 1  | 2  | 3  | 4  | âœ˜      |
| 2   | 1  | 2  | 3  | 4  | âœ˜      |
| 5   | 5  | 2  | 3  | 4  | âœ”      |
| 1   | 5  | 1  | 3  | 4  | âœ”      |
| 2   | 5  | 1  | 2  | 4  | âœ”      |
| 3   | 5  | 1  | 2  | 3  | âœ”      |
| 4   | 4  | 1  | 2  | 3  | âœ”      |
| 5   | 4  | 5  | 2  | 3  | âœ”      |
:::


:::
:::

## Buffering de pÃ gines (I) {.smaller}

El buffering de pÃ gines Ã©s una tÃ¨cnica que intenta reduir el cost de les fallades de pÃ gina mantenint una reserva de marcs lliures.

Quan es produeix una fallada de pÃ gina:

- No cal executar immediatament lâ€™algorisme de reemplaÃ§ament.
- El SO assigna un marc de la reserva, reduint la latÃ¨ncia percebuda pel procÃ©s.

:::{.fragment .center-container}
Sâ€™utilitza un marc lliure, perÃ² encara no sâ€™ha alliberat cap pÃ gina resident.
:::

## Buffering de pÃ gines (II) {.smaller}

Quan el nombre de marcs lliures cau per sota dâ€™un llindar $\theta$, el SO:

1. Activa lâ€™algorisme de reemplaÃ§ament.
2. Recull pÃ gines no modificades â†’ van a la free list.
3. Recull pÃ gines modificades â†’ van a la modified list, on es mantenen fins que sâ€™escriuen al disc.
4. Una pÃ gina que es trobi en alguna llista (lliure o modificada) pot ser recuperada rÃ pidament si es torna a referenciar.

:::{.fragment .center-container}
El buffering converteix el reemplaÃ§ament **immediat** en un procÃ©s diferit, suavitzant lâ€™impacte de les fallades.
:::

## Ex07: Buffering de pÃ gines {.smaller}

Suposem un sistema amb una MemÃ²ria Principal amb  6 marcs i una $\theta=2$. Utilitzarem l'algorisme FIFO per gestionar el reemplaÃ§ament de pÃ gines.

- **InicialitzaciÃ³**:
  - **MP**: [ ] [ ] [ ] [ ] [ ] [ ]
  - **Free list**: [F1,F2,F3,F4,F5,F6]
  - **Modified list**: [ ]
- **Carreguem P1 i P2**:
  - **MP**: [P1] [P2] [ ] [ ] [ ] [ ]
  - **Free list**: [F3,F4,F5,F6]
  - **Modified list**: [ ]
  - Cap reempaÃ§ament necessari.

## Ex07: Buffering de pÃ gines {.smaller}

- **Carreguem P3 i P4**:
  - **MP**: [P1] [P2] [P3] [P4] [ ] [ ]
  - **Free list**: [F5,F6]
  - **Modified list**: [ ]
  - Encara $\geq \theta$ (Free list = 2).

- **Carreguem P5 i P6**:
  - **MP**: [P1] [P2] [P3] [P4] [P5] [P6]
  - **Free list**: [ ]
  - **Modified list**: [ ]
  - Ara < $\theta$ (Free list = 0) â†’ activem reemplaÃ§ament.
  - Assumirem que cap pÃ gina estÃ  modificada.

## Ex07: Buffering de pÃ gines {.smaller}

- **FIFO reemplaÃ§ament**: P1 â†’ P2 â†’ P3 â†’ P4 â†’ P5 â†’ P6
  - Expulsem P1:
    - **MP**: [] [P2] [P3] [P4] [P5] [P6]
    - **Free list**: [F1]
    - **Modified list**: [ ]
    - Encara < $\theta$ â†’ continuem reemplaÃ§ant.
  - Expulsem P2:
    - **MP**: [] [] [P3] [P4] [P5] [P6]
    - **Free list**: [F1,F2]
    - **Modified list**: [ ]
    - Ara $\geq \theta$ â†’ aturem reemplaÃ§ament.

## Ex07: Buffering de pÃ gines {.smaller}

- **Carreguem P7**:
  - Agafem un marc lliure de la free list (F1):
  - **MP**: [P7] [] [P3] [P4] [P5] [P6]
  - **Free list**: [F2]
  - **Modified list**: [ ]
  - Com free list = 1 < $\theta$ â†’ activem reemplaÃ§ament.
- **FIFO reemplaÃ§ament**: Expulsem P3:
  - **MP**: [P7] [] [] [P4] [P5] [P6]
  - **Free list**: [F2,F3]
  - **Modified list**: [ ]
  - Ara $\geq \theta$ â†’ aturem reemplaÃ§ament.

## Ex07: Buffering de pÃ gines {.smaller}

- **Carreguem P8**:
    - Agafem un marc lliure de la free list (F2):
    - **MP**: [P7] [P8] [] [P4] [P5] [P6]
    - **Free list**: [F3]
    - **Modified list**: [ ]
    - Com free list = 1 < $\theta$ â†’ activem reemplaÃ§ament.
- **FIFO reemplaÃ§ament**: Expulsem P4:
    - **MP**: [P7] [P8] [] [] [P5] [P6]
    - **Free list**: [F3,F4]
    - **Modified list**: [ ]
    - Ara $\geq \theta$ â†’ aturem reemplaÃ§ament.

## RetenciÃ³ de pÃ gines {.smaller}

- No totes les pÃ gines poden ser expulsades:
- Algunes pÃ gines del SO no sÃ³n reemplaÃ§ables.
- Certes aplicacions necessiten residÃ¨ncia garantida (real-time, dispositius, memÃ²ria crÃ­tica).

:::{.fragment}
Una aplicaciÃ³ pot demanar que determinades pÃ gines no surtin mai de la MP:

```c
#include <sys/mman.h>
int mlock(const void *addr, size_t len);
```
:::


:::{.fragment .center-container}
La retenciÃ³ garanteix latÃ¨ncia baixa i evita fallades crÃ­tiques.
:::
 
## Ex08: Calcul del nombre de fallades {.smaller}

- Disposem d'un sistema amb **paginaciÃ³ sota demanda**.
- Mida de pÃ gina = 200 paraules
- AssignaciÃ³ local igualitÃ ria amb 3 celÂ·les per procÃ©s.
- Lâ€™algorisme de reemplaÃ§ament Ã©s LRU. 
- Cada paraula ocupa 1 byte i cada enter ocupa 1 byte.

:::{.fragment}
```c
main() {
    int i, j, A[100][100];
    for (i=0; i<100; i++)
        for (j=0; j<100; j++)
            A[i][j] = 0;
}
```
:::

:::{.fragment}
Assumim que **i** i **j** estan en registres i no ocupen memÃ²ria. La matriu A estÃ  emmagatzemada per files (*row-major*).
:::

## Ex08: Calcul del nombre de fallades {.smaller}

- La matriu A tÃ© 100x100 = 10.000 enters â†’ ocupa 10.000 paraules.
- Mida de pÃ gina = 200 paraules â†’ $200\frac{enters}{pÃ gina}$.
- Nombre de pÃ gines necessÃ ries per a A: $\frac{10.000 paraules}{200\frac{paraules}{pÃ gina}} = 50 pÃ gines$.

- Cada fila ocupa 100 bytes. Com que una pÃ gina contÃ© 200 bytes,cada pÃ gina contÃ© exactament 2 files completes.
  - PÃ gina 0 contÃ© A[0][0] a A[1][99]
  - La pÃ gina 1 contÃ© A[2][0] a A[3][99]
  - ...
- El bucle recorregut fila a fila provoca que cada 2 files sâ€™accedeixi a una nova pÃ gina.

## Ex08: Calcul del nombre de fallades {.smaller}

:::{.fragment .callout-warning title="Resultat"}
Per tant, hi haurÃ  una fallada de pÃ gina cada 2 files. Amb 100 files, hi haurÃ  50 fallades de pÃ gina en total sobre l'accÃ©s a la matriu A.
:::

:::{.fragment .callout-note title="Nota"}
Si vols comptar tambÃ© la possible fallada inicial per carregar codi/taules del procÃ©s a MP, sâ€™hi pot sumar 1 â†’ 51 en total.
:::

## Ex08: Comportament amb 3 marcs i LRU {.smaller}

- Els 3 marcs assignats al procÃ©s no redueixen aquest nombre de misses en aquest patrÃ³ seqÃ¼encial: cada pÃ gina sâ€™accedeix una sola vegada i no hi ha *reuse*, de manera que LRU (amb 3 marcs) carregarÃ  cada pÃ gina exactament un cop.
- Durant lâ€™execuciÃ³, desprÃ©s dâ€™omplir els 3 marcs, cada nova pÃ gina expulsarÃ  la menys recentment utilitzada (equivalent, en aquest cas seqÃ¼encial, a expulsar la mÃ©s antiga entre les resident).

:::{.fragment}
```text
i=0 â†’ pÃ gina 0 â†’ fallada
i=1 â†’ mateixa pÃ gina â†’ hit
i=2 â†’ pÃ gina 1 â†’ fallada
i=3 â†’ hit
i=4 â†’ pÃ gina 2 â†’ fallada
i=5 â†’ mateixa pÃ gina â†’ hit
i=6 â†’ pÃ gina 3 â†’ fallada + expulsa pÃ gina 0
i=7 â†’ mateixa pÃ gina â†’ hit
â€¦
i=98 â†’ pÃ gina 49 â†’ fallada + expulsa pÃ gina 47
i=99 â†’ mateixa pÃ gina â†’ hit
```
:::

## Ex09: Calcul del nombre de fallades {.smaller}

Repeteix els cÃ lculs anteriors perÃ² assumint que ara la matriu A estÃ  emmagatzemada per columnes (*column-major*).

```c
main() {
    int i, j, A[100][100];
    for (i=0; i<100; i++)
        for (j=0; j<100; j++)
            A[i][j] = 0;
}
```


## Ex09: Calcul del nombre de fallades {.smaller}

En *column-major*, la memÃ²ria sâ€™organitza per columnes: les posicions consecutives corresponen a A[0][c], A[1][c], A[2][c], â€¦.

Cada columna tÃ© 100 enters; cada pÃ gina contÃ© 200 enters â†’ cada pÃ gina contÃ© 2 columnes:

- pÃ gina 0 â†’ columnes 0 i 1 de totes les files A[0] A[1]
- pÃ gina 1 â†’ columnes 2 i 3 de totes les files A[2] A[3]
- â€¦
- pÃ gina 49 â†’ columnes 98 i 99 de totes les files A[98] A[99]

:::{.fragment .callout-warning}
El patrÃ³ dâ€™accÃ©s generat pel doble bucle (primer i, desprÃ©s j) visita les celÂ·les en ordre:
*A[0][0], A[0][1], A[0][2], â€¦, A[0][99], A[1][0], A[1][1], â€¦, A[99][99]*
Per a *column-major* aixÃ² significa: per una fila fixa i anem saltant entre columnes i, per tant, entre moltes pÃ gines diferents.
:::

## Ex09: Calcul del nombre de fallades {.smaller}

- Per una fila i fixa la seqÃ¼Ã¨ncia de pÃ gines Ã©s: **p(0), p(1), p(2), ..., p(49)**

- Cada pÃ gina p(k) sâ€™accedeix dues vegades consecutives per cada fila i (per j=0 i j=1)

- 1a utilitzaciÃ³ de p(k) â†’ fallada (ja que no estÃ  a MP)
- 2a utilitzaciÃ³ de p(k) â†’ hit (ja que acaba de ser carregada) 
- La proper reutilitzaciÃ³ de p(k) es produeix nomÃ©s a la fila segÃ¼ent (i+1), desprÃ©s dâ€™haver visitat totes les altres pÃ gines  entre mig.
- La reuse distance (nombre de pÃ gines Ãºniques entre dues utilitzacions de la mateixa pÃ gina) Ã©s 49.
- Com que els marcs assignats = 3 i 49 > 3, LRU no pot retenir p(k) fins al seu prÃ²xim Ãºs â†’ la pÃ gina serÃ  expulsada abans de la segÃ¼ent reutilitzaciÃ³.

## Ex09: Calcul del nombre de fallades {.smaller}

- Cada fila $i$ provoca 50 fallades de pÃ gina (una per cada pÃ gina p(0) a p(49)).
- Per cada pÃ gina p(k), en una fila $i$ sâ€™accedeix dues vegades (j=0 i j=1):
  - 1a accÃ©s â†’ fallada
  - 2a accÃ©s â†’ hit (immediatament desprÃ©s)
- Per fila, hi ha 50 misses  (1 per cada pÃ gina).
- Amb 100 files, el total de fallades Ã©s: $100 \text{ files} \times 50 \text{ fallades/fila} = 5000 \text{ fallades}$.

:::{.fragment .callout-note title="ConclusiÃ³"}
En *column-major*, amb 3 marcs i LRU, es produeixen 5000 fallades de pÃ gina en total, o 5001 si comptem la possible fallada inicial per carregar codi/taules del procÃ©s a MP.
:::

## HiperpaginaciÃ³ {.smaller}

La hiperpaginaciÃ³ Ã©s un estat del sistema en quÃ¨ el nombre de fallades de pÃ gina Ã©s tan elevat que:

::: columns
::: {.column width="50%"}

![](../figures/slides/06-mem/virtual/hiperpaginacio.png)

:::
::: {.column width="50%"}

- La taxa dâ€™Ãºs de CPU disminueix drÃ sticament, i
- El dispositiu de paginaciÃ³ (disc/SSD) treballa de manera gairebÃ© contÃ­nua.

:::
:::

:::{.fragment}
AixÃ² passa quan els processos no disposen del nombre mÃ­nim de marcs necessaris per mantenir resident el seu conjunt de treball, i cada accÃ©s provoca una fallada immediata.
:::

:::{.fragment .callout-warning title="CaracteritzaciÃ³"}
Un sistema estÃ  en hiperpaginaciÃ³ quan el temps invertit en gestionar fallades de pÃ gina Ã©s superior al temps Ãºtil d'execuciÃ³ dels processos.
:::

## Model PFF {.smaller}

Per controlar lâ€™estat del sistema, molts SO utilitzen la PFF (*Page Fault Frequency*) com a criteri de regulaciÃ³ de marcs.

$$PFF = \frac{Nombre\ de\ fallades\ de\ pÃ gina}{Temps\ d\ 'execuciÃ³\ del\ procÃ©s}$$

::: columns
::: {.column width="35%"}
Cada procÃ©s tÃ© dos llindars:

- Llindar inferior ($L_{inf}$)
- Llindar superior ($L_{sup}$)
- Lâ€™objectiu Ã©s mantenir cada procÃ©s dins dâ€™una zona estable on la seva freqÃ¼Ã¨ncia de fallades sigui acceptable.


:::
::: {.column width="65%"}

:::{.fragment}
Si PFF < $L_{inf}$

- el procÃ©s tÃ© mÃ©s marcs dels que necessita
- el sistema pot retirar marcs al procÃ©s o augmentar multiprogramaciÃ³
:::

:::{.fragment}
Si PFF > $L_{sup}$

- el procÃ©s no mantÃ© el conjunt de treball
- es produeix degradaciÃ³ severa
- cal assignar mÃ©s marcs o suspendre el procÃ©s
:::

:::
:::



## Ex: IdentificaciÃ³ dâ€™hiperpaginaciÃ³ {.smaller}

Disposem de les segÃ¼ents mesures dâ€™un sistema amb MemÃ²ria Virtual:

- Ãšs de CPU = 15%
- OcupaciÃ³ del dispositiu de paginaciÃ³ = 97%
- Determinar lâ€™estat del sistema i justificar-lo.

## Ex: IdentificaciÃ³ dâ€™hiperpaginaciÃ³ {.smaller}

- Una CPU amb una taxa dâ€™utilitzaciÃ³ del 15% indica que els processos no estan executant instruccions, sinÃ³ que es troben majoritÃ riament bloquejats.

- Un dispositiu de paginaciÃ³ amb una ocupaciÃ³ del 97% indica que el SO estÃ  dedicat quasi exclusivament a servir operacions de lectura/escriptura de pÃ gines.

:::{.fragment .callout-warning title="ConclusiÃ³"}
- El sistema es troba en estat de hiperpaginaciÃ³.
- Els processos no disposen de prou marcs per mantenir el seu conjunt de treball i generen fallades contÃ­nues.
:::

:::{.fragment .callout-note title="Mesura correctiva"}
Cal reduir el grau de multiprogramaciÃ³, tÃ­picament mitjanÃ§ant:

- SuspensiÃ³ temporal de processos
- RedistribuciÃ³ de marcs
- ReducciÃ³ del nombre de processos actius
:::

